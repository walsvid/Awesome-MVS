# Awesome-MVS

<!-- 
pdf f5cac3
zip cfbaf0
![](https://img.shields.io/badge/Official-white.svg?logoColor=white&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxNiAxNiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2IiBmaWxsPSIjNTNBMTU4Ij48cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xLjUgOGE2LjUgNi41IDAgMTExMyAwIDYuNSA2LjUgMCAwMS0xMyAwek0wIDhhOCA4IDAgMTExNiAwQTggOCAwIDAxMCA4em0xMS43OC0xLjcyYS43NS43NSAwIDAwLTEuMDYtMS4wNkw2Ljc1IDkuMTkgNS4yOCA3LjcyYS43NS43NSAwIDAwLTEuMDYgMS4wNmwyIDJhLjc1Ljc1IDAgMDAxLjA2IDBsNC41LTQuNXoiPjwvcGF0aD48L3N2Zz4=)

https://img.shields.io/badge/Other-white.svg?logoColor=white&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA1MTIgNTEyIiB3aWR0aD0iMjQiIGhlaWdodD0iMjQiPjxwYXRoIGQ9Ik0yNTYgMEMxMTQuNiAwIDAgMTE0LjYgMCAyNTZzMTE0LjYgMjU2IDI1NiAyNTZzMjU2LTExNC42IDI1Ni0yNTZTMzk3LjQgMCAyNTYgMHpNMjU2IDQwMGMtMTggMC0zMi0xNC0zMi0zMnMxMy4xLTMyIDMyLTMyYzE3LjEgMCAzMiAxNCAzMiAzMlMyNzMuMSA0MDAgMjU2IDQwMHpNMzI1LjEgMjU4TDI4MCAyODZWMjg4YzAgMTMtMTEgMjQtMjQgMjRTMjMyIDMwMSAyMzIgMjg4VjI3MmMwLTggNC0xNiAxMi0yMWw1Ny0zNEMzMDggMjEzIDMxMiAyMDYgMzEyIDE5OEMzMTIgMTg2IDMwMS4xIDE3NiAyODkuMSAxNzZoLTUxLjFDMjI1LjEgMTc2IDIxNiAxODYgMjE2IDE5OGMwIDEzLTExIDI0LTI0IDI0cy0yNC0xMS0yNC0yNEMxNjggMTU5IDE5OSAxMjggMjM3LjEgMTI4aDUxLjFDMzI5IDEyOCAzNjAgMTU5IDM2MCAxOThDMzYwIDIyMiAzNDcgMjQ1IDMyNS4xIDI1OHoiLz48L3N2Zz4=

-->

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

## Learning-based MVS Methods

### 2018

#### MVSNet: Depth Inference for Unstructured Multi-view Stereo

- ![Publication](https://img.shields.io/badge/2018-ECCV-f3722c) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_ECCV_2018/papers/Yao_Yao_MVSNet_Depth_Inference_ECCV_2018_paper.pdf) [![Paper](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://yoyo000.github.io/papers/yao2018mvsnet_supp.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1804.02505-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/1804.02505)
- ![Tensorflow](https://img.shields.io/badge/TensorFlow-ff6f00?logo=tensorflow&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/YoYo000/MVSNet?logo=github&label=Stars)](https://github.com/YoYo000/MVSNet) ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/xy-guo/MVSNet_pytorch?logo=github&label=Stars)](https://github.com/xy-guo/MVSNet_pytorch)
- [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/mvsnet-depth-inference-for-unstructured-multi/3d-reconstruction-on-dtu)](https://paperswithcode.com/sota/3d-reconstruction-on-dtu?p=mvsnet-depth-inference-for-unstructured-multi) [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/mvsnet-depth-inference-for-unstructured-multi/point-clouds-on-tanks-and-temples)](https://paperswithcode.com/sota/point-clouds-on-tanks-and-temples?p=mvsnet-depth-inference-for-unstructured-multi)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/%E6%88%AA%E5%B1%8F2022-03-05%2016.56.16.png)

### 2019

#### Recurrent MVSNet for High-resolution Multi-view Stereo Depth Inference

- ![Publication](https://img.shields.io/badge/2019-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2019/papers/Yao_Recurrent_MVSNet_for_High-Resolution_Multi-View_Stereo_Depth_Inference_CVPR_2019_paper.pdf) [![Paper](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Yao_Recurrent_MVSNet_for_CVPR_2019_supplemental.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1902.10556-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/1902.10556)
- ![Tensorflow](https://img.shields.io/badge/TensorFlow-ff6f00?logo=tensorflow&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/YoYo000/MVSNet?logo=github&label=Stars)](https://github.com/YoYo000/MVSNet)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/%E6%88%AA%E5%B1%8F2022-03-05%2017.46.26.png)

#### Point-Based Multi-View Stereo Network

- ![Publication](https://img.shields.io/badge/2019-ICCV-f9c74f) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Point-Based_Multi-View_Stereo_Network_ICCV_2019_paper.pdf) [![Paper](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Chen_Point-Based_Multi-View_Stereo_ICCV_2019_supplemental.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1908.04422-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/1908.04422) ![Publication](https://img.shields.io/badge/2020-T--PAMI-7209b7) [![Paper](https://img.shields.io/badge/Journal-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://ieeexplore.ieee.org/abstract/document/9076298)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/callmeray/PointMVSNet?logo=github&label=Stars)](https://github.com/callmeray/PointMVSNet)
- [![Video](https://img.shields.io/badge/Youtube-Video-cc0000?style=flat&logo=youtube&logoColor=cc0000)](https://www.youtube.com/watch?v=my3jocjpD0U) [![Webpage](https://img.shields.io/badge/Project-Page-3cba54?style=flat&logo=Google%20chrome&logoColor=white)](http://hansf.me/projects/PMVSNet/)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220305175706.png)

#### P-MVSNet: Learning Patch-wise Matching Confidence Aggregation for Multi-view Stereo

- ![Publication](https://img.shields.io/badge/2019-ICCV-f9c74f) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_ICCV_2019/papers/Luo_P-MVSNet_Learning_Patch-Wise_Matching_Confidence_Aggregation_for_Multi-View_Stereo_ICCV_2019_paper.pdf)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314143735.png)

#### MVSCRF: Learning Multi-view Stereo with Conditional Random Fields

- ![Publication](https://img.shields.io/badge/2019-ICCV-f9c74f) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_ICCV_2019/papers/Xue_MVSCRF_Learning_Multi-View_Stereo_With_Conditional_Random_Fields_ICCV_2019_paper.pdf)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314145514.png)

#### Learning unsupervised multi-view stereopsis via robust photometric consistency

- ![Publication](https://img.shields.io/badge/2019-CoRR-b31b1b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.1905.02706-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/1905.02706)
- ![Tensorflow](https://img.shields.io/badge/TensorFlow-ff6f00?logo=tensorflow&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/tejaskhot/unsup_mvs?logo=github&label=Stars)](https://github.com/tejaskhot/unsup_mvs)
- ![SelfSup](https://img.shields.io/badge/Self--Surpervised-ffe169.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA2NDAgNTEyIj48cGF0aCBkPSJNNDk0LjkgOTYuMDFjLTM4Ljc4IDAtNzUuMjIgMTUuMDktMTAyLjYgNDIuNUwzMjAgMjEwLjhMMjQ3LjggMTM4LjVjLTI3LjQxLTI3LjQxLTYzLjg0LTQyLjUtMTAyLjYtNDIuNUM2NS4xMSA5Ni4wMSAwIDE2MS4xIDAgMjQxLjF2MjkuNzVjMCA4MC4wMyA2NS4xMSAxNDUuMSAxNDUuMSAxNDUuMWMzOC43OCAwIDc1LjIyLTE1LjA5IDEwMi42LTQyLjVMMzIwIDMwMS4zbDcyLjIzIDcyLjI1YzI3LjQxIDI3LjQxIDYzLjg0IDQyLjUgMTAyLjYgNDIuNUM1NzQuOSA0MTYgNjQwIDM1MC45IDY0MCAyNzAuOXYtMjkuNzVDNjQwIDE2MS4xIDU3NC45IDk2LjAxIDQ5NC45IDk2LjAxek0yMDIuNSAzMjguM2MtMTUuMzEgMTUuMzEtMzUuNjkgMjMuNzUtNTcuMzggMjMuNzVDMTAwLjQgMzUyIDY0IDMxNS42IDY0IDI3MC45di0yOS43NWMwLTQ0LjcyIDM2LjQxLTgxLjEzIDgxLjE0LTgxLjEzYzIxLjY5IDAgNDIuMDYgOC40MzggNTcuMzggMjMuNzVsNzIuMjMgNzIuMjVMMjAyLjUgMzI4LjN6TTU3NiAyNzAuOWMwIDQ0LjcyLTM2LjQxIDgxLjEzLTgxLjE0IDgxLjEzYy0yMS42OSAwLTQyLjA2LTguNDM4LTU3LjM4LTIzLjc1bC03Mi4yMy03Mi4yNWw3Mi4yMy03Mi4yNWMxNS4zMS0xNS4zMSAzNS42OS0yMy43NSA1Ny4zOC0yMy43NUM1MzkuNiAxNjAgNTc2IDE5Ni40IDU3NiAyNDEuMVYyNzAuOXoiLz48L3N2Zz4=)
[![Webpage](https://img.shields.io/badge/Project-Page-3cba54?style=flat&logo=Google%20chrome&logoColor=white)](https://tejaskhot.github.io/unsup_mvs/)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/2%E6%88%AA%E5%B1%8F2022-03-14%2016.51.16.png)

#### MVS2: Deep Unsupervised Multi-View Stereo with Multi-View Symmetry

- ![Publication](https://img.shields.io/badge/2019-3DV-277da1) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://ieeexplore.ieee.org/abstract/document/8885975) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1908.11526-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/1908.11526)
- ![SelfSup](https://img.shields.io/badge/Self--Surpervised-ffe169.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA2NDAgNTEyIj48cGF0aCBkPSJNNDk0LjkgOTYuMDFjLTM4Ljc4IDAtNzUuMjIgMTUuMDktMTAyLjYgNDIuNUwzMjAgMjEwLjhMMjQ3LjggMTM4LjVjLTI3LjQxLTI3LjQxLTYzLjg0LTQyLjUtMTAyLjYtNDIuNUM2NS4xMSA5Ni4wMSAwIDE2MS4xIDAgMjQxLjF2MjkuNzVjMCA4MC4wMyA2NS4xMSAxNDUuMSAxNDUuMSAxNDUuMWMzOC43OCAwIDc1LjIyLTE1LjA5IDEwMi42LTQyLjVMMzIwIDMwMS4zbDcyLjIzIDcyLjI1YzI3LjQxIDI3LjQxIDYzLjg0IDQyLjUgMTAyLjYgNDIuNUM1NzQuOSA0MTYgNjQwIDM1MC45IDY0MCAyNzAuOXYtMjkuNzVDNjQwIDE2MS4xIDU3NC45IDk2LjAxIDQ5NC45IDk2LjAxek0yMDIuNSAzMjguM2MtMTUuMzEgMTUuMzEtMzUuNjkgMjMuNzUtNTcuMzggMjMuNzVDMTAwLjQgMzUyIDY0IDMxNS42IDY0IDI3MC45di0yOS43NWMwLTQ0LjcyIDM2LjQxLTgxLjEzIDgxLjE0LTgxLjEzYzIxLjY5IDAgNDIuMDYgOC40MzggNTcuMzggMjMuNzVsNzIuMjMgNzIuMjVMMjAyLjUgMzI4LjN6TTU3NiAyNzAuOWMwIDQ0LjcyLTM2LjQxIDgxLjEzLTgxLjE0IDgxLjEzYy0yMS42OSAwLTQyLjA2LTguNDM4LTU3LjM4LTIzLjc1bC03Mi4yMy03Mi4yNWw3Mi4yMy03Mi4yNWMxNS4zMS0xNS4zMSAzNS42OS0yMy43NSA1Ny4zOC0yMy43NUM1MzkuNiAxNjAgNTc2IDE5Ni40IDU3NiAyNDEuMVYyNzAuOXoiLz48L3N2Zz4=)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220315002311.png)

### 2020

#### MVSNet++: Learning Depth-Based Attention Pyramid Features for Multi-View Stereo

- ![Publication](https://img.shields.io/badge/2020-T--IP-9a8c98) [![Paper](https://img.shields.io/badge/Journal-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://ieeexplore.ieee.org/document/9115828)
- [![Video](https://img.shields.io/badge/Youtube-Video-cc0000?style=flat&logo=youtube&logoColor=cc0000)](https://www.youtube.com/watch?v=VRTEWxt1P68)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314221417.png)

#### PVSNet: Pixelwise Visibility-Aware Multi-View Stereo Network

- ![Publication](https://img.shields.io/badge/2020-CoRR-b31b1b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.2007.07714-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2007.07714)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314232551.png)

#### Cascade Cost Volume for High-Resolution Multi-View Stereo and Stereo Matching

- ![Publication](https://img.shields.io/badge/2020-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2020/papers/Gu_Cascade_Cost_Volume_for_High-Resolution_Multi-View_Stereo_and_Stereo_Matching_CVPR_2020_paper.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1912.06378-B31B1B?logo=arXiv&logoColor=green)](http://arxiv.org/abs/1912.06378)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/alibaba/cascade-stereo?logo=github&label=Stars)](https://github.com/alibaba/cascade-stereo)
- [![Video](https://img.shields.io/badge/Youtube-Video-cc0000?style=flat&logo=youtube&logoColor=cc0000)](https://www.youtube.com/watch?v=rcJiRQqDKbo)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220306002513.png)

#### Deep Stereo using Adaptive Thin Volume Representation with Uncertainty Awareness - [UCSNet]

- ![Publication](https://img.shields.io/badge/2020-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2020/papers/Cheng_Deep_Stereo_Using_Adaptive_Thin_Volume_Representation_With_Uncertainty_Awareness_CVPR_2020_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Cheng_Deep_Stereo_Using_CVPR_2020_supplemental.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1911.12012-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/1911.12012)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/touristCheng/UCSNet?logo=github&label=Stars)](https://github.com/touristCheng/UCSNet)
- [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/deep-stereo-using-adaptive-thin-volume/3d-reconstruction-on-dtu)](https://paperswithcode.com/sota/3d-reconstruction-on-dtu?p=deep-stereo-using-adaptive-thin-volume) [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/deep-stereo-using-adaptive-thin-volume/point-clouds-on-tanks-and-temples)](https://paperswithcode.com/sota/point-clouds-on-tanks-and-temples?p=deep-stereo-using-adaptive-thin-volume)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314150037.png)

#### Fast-MVSNet: Sparse-to-Dense Multi-View Stereo with Learned Propagation and Gauss-Newton Refinement

- ![Publication](https://img.shields.io/badge/2020-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yu_Fast-MVSNet_Sparse-to-Dense_Multi-View_Stereo_With_Learned_Propagation_and_Gauss-Newton_Refinement_CVPR_2020_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Yu_Fast-MVSNet_Sparse-to-Dense_Multi-View_CVPR_2020_supplemental.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2003.13017-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2003.13017)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/svip-lab/FastMVSNet?logo=github&label=Stars)](https://github.com/svip-lab/FastMVSNet)
- [![Video](https://img.shields.io/badge/Youtube-Video-cc0000?style=flat&logo=youtube&logoColor=cc0000)](https://www.youtube.com/watch?v=34c3Vf9g7kM)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314151052.png)

#### Learning Inverse Depth Regression for Multi-View Stereo with Correlation Cost Volume

- ![Publication](https://img.shields.io/badge/2020-AAAI-ffafcc) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://ojs.aaai.org//index.php/AAAI/article/view/6939/6793) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1912.11746-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/1912.11746)
- ![Other](https://img.shields.io/badge/Other-white.svg?logoColor=white&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA1MTIgNTEyIiB3aWR0aD0iMjQiIGhlaWdodD0iMjQiPjxwYXRoIGQ9Ik0yNTYgMEMxMTQuNiAwIDAgMTE0LjYgMCAyNTZzMTE0LjYgMjU2IDI1NiAyNTZzMjU2LTExNC42IDI1Ni0yNTZTMzk3LjQgMCAyNTYgMHpNMjU2IDQwMGMtMTggMC0zMi0xNC0zMi0zMnMxMy4xLTMyIDMyLTMyYzE3LjEgMCAzMiAxNCAzMiAzMlMyNzMuMSA0MDAgMjU2IDQwMHpNMzI1LjEgMjU4TDI4MCAyODZWMjg4YzAgMTMtMTEgMjQtMjQgMjRTMjMyIDMwMSAyMzIgMjg4VjI3MmMwLTggNC0xNiAxMi0yMWw1Ny0zNEMzMDggMjEzIDMxMiAyMDYgMzEyIDE5OEMzMTIgMTg2IDMwMS4xIDE3NiAyODkuMSAxNzZoLTUxLjFDMjI1LjEgMTc2IDIxNiAxODYgMjE2IDE5OGMwIDEzLTExIDI0LTI0IDI0cy0yNC0xMS0yNC0yNEMxNjggMTU5IDE5OSAxMjggMjM3LjEgMTI4aDUxLjFDMzI5IDEyOCAzNjAgMTU5IDM2MCAxOThDMzYwIDIyMiAzNDcgMjQ1IDMyNS4xIDI1OHoiLz48L3N2Zz4=) [![GitHub stars](https://img.shields.io/github/stars/GhiXu/CIDER?logo=github&label=Stars)](https://github.com/GhiXu/CIDER)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/%E6%88%AA%E5%B1%8F2022-03-14%2015.16.20.png)

#### Attention-Aware Multi-View Stereo - [AttMVSNet]

- ![Publication](https://img.shields.io/badge/2020-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2020/papers/Luo_Attention-Aware_Multi-View_Stereo_CVPR_2020_paper.pdf)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314152022.png)

#### A Novel Recurrent Encoder-Decoder Structure for Large-Scale Multi-view Stereo Reconstruction from An Open Aerial Dataset

- ![Publication](https://img.shields.io/badge/2020-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_A_Novel_Recurrent_Encoder-Decoder_Structure_for_Large-Scale_Multi-View_Stereo_Reconstruction_CVPR_2020_paper.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2003.00637-B31B1B?logo=arXiv&logoColor=green)](http://arxiv.org/abs/2003.00637)
- ![Tensorflow](https://img.shields.io/badge/TensorFlow-ff6f00?logo=tensorflow&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/gpcv-liujin/REDNet?logo=github&label=Stars)](https://github.com/gpcv-liujin/REDNet)
- [![Video](https://img.shields.io/badge/Youtube-Video-cc0000?style=flat&logo=youtube&logoColor=cc0000)](https://www.youtube.com/watch?v=gZds3nKoPR8)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314152327.png)

#### Cost Volume Pyramid Based Depth Inference for Multi-View Stereo - [CVP-MVSNet]

- ![Publication](https://img.shields.io/badge/2020-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_Cost_Volume_Pyramid_Based_Depth_Inference_for_Multi-View_Stereo_CVPR_2020_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Yang_Cost_Volume_Pyramid_CVPR_2020_supplemental.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1912.08329-B31B1B?logo=arXiv&logoColor=green)](http://arxiv.org/abs/1912.08329)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/JiayuYANG/CVP-MVSNet?logo=github&label=Stars)](https://github.com/JiayuYANG/CVP-MVSNet)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314203554.png)

#### Pyramid Multi-view Stereo Net with Self-adaptive View aggregation - [PVAMVSNet]

- ![Publication](https://img.shields.io/badge/2020-ECCV-f3722c) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123540732.pdf) [![Supp](https://img.shields.io/badge/Supplementary-ZIP-b5e48c)](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123540732-supp.zip) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1912.03001-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/1912.03001)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/yhw-yhw/PVAMVSNet?logo=github&label=Stars)](https://github.com/yhw-yhw/PVAMVSNet)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314152622.png)

#### Dense Hybrid Recurrent Multi-view Stereo Net with Dynamic Consistency Checking

- ![Publication](https://img.shields.io/badge/2020-ECCV-f3722c) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490647.pdf) [![Supp](https://img.shields.io/badge/Supplementary-ZIP-b5e48c)](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490647-supp.zip) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2007.10872-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2007.10872)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/yhw-yhw/D2HC-RMVSNet?logo=github&label=Stars)](https://github.com/yhw-yhw/D2HC-RMVSNet)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314180115.png)

#### Visibility-aware Multi-view Stereo Network - [Vis-MVSNet]

- ![Publication](https://img.shields.io/badge/2020-BMVC-b98b73) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://www.bmvc2020-conference.com/assets/papers/0421.pdf) [![Supp](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://www.bmvc2020-conference.com/assets/supp/0421_supp.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2008.0792-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2008.0792)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/jzhangbs/Vis-MVSNet?logo=github&label=Stars)](https://github.com/jzhangbs/Vis-MVSNet)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314184438.png)

### 2021

#### Long-range Attention Network for Multi-View Stereo

- ![Publication](https://img.shields.io/badge/2021-WACV-9d4edd) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/WACV2021/papers/Zhang_Long-Range_Attention_Network_for_Multi-View_Stereo_WACV_2021_paper.pdf)
- [![Video](https://img.shields.io/badge/Youtube-Video-cc0000?style=flat&logo=youtube&logoColor=cc0000)](https://www.youtube.com/watch?v=BfwBth3HgQU)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314201531.png)

#### PatchmatchNet: Learned Multi-View Patchmatch Stereo

- ![Publication](https://img.shields.io/badge/2021-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_PatchmatchNet_Learned_Multi-View_Patchmatch_Stereo_CVPR_2021_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/CVPR2021/supplemental/Wang_PatchmatchNet_Learned_Multi-View_CVPR_2021_supplemental.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2012.01411-B31B1B?logo=arXiv&logoColor=green)](http://arxiv.org/abs/2012.01411)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/FangjinhuaWang/PatchmatchNet?logo=github&label=Stars)](https://github.com/FangjinhuaWang/PatchmatchNet)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314202133.png)

#### DeepVideoMVS: Multi-View Stereo on Video With Recurrent Spatio-Temporal Fusion

- ![Publication](https://img.shields.io/badge/2021-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/CVPR2021/papers/Duzceker_DeepVideoMVS_Multi-View_Stereo_on_Video_With_Recurrent_Spatio-Temporal_Fusion_CVPR_2021_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/CVPR2021/supplemental/Duzceker_DeepVideoMVS_Multi-View_Stereo_CVPR_2021_supplemental.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2012.02177-B31B1B?logo=arXiv&logoColor=green)](http://arxiv.org/abs/2012.02177)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/ardaduz/deep-video-mvs?logo=github&label=Stars)](https://github.com/ardaduz/deep-video-mvs)
- [![Video](https://img.shields.io/badge/Youtube-Video-cc0000?style=flat&logo=youtube&logoColor=cc0000)](https://www.youtube.com/watch?v=ikpotjxwcp4)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314202836.png)

#### Self-Supervised Learning of Depth Inference for Multi-View Stereo

- ![Publication](https://img.shields.io/badge/2021-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Self-Supervised_Learning_of_Depth_Inference_for_Multi-View_Stereo_CVPR_2021_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/CVPR2021/supplemental/Yang_Self-Supervised_Learning_of_CVPR_2021_supplemental.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2104.02972-B31B1B?logo=arXiv&logoColor=green)](http://arxiv.org/abs/2104.02972)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/JiayuYANG/Self-supervised-CVP-MVSNet?logo=github&label=Stars)](https://github.com/JiayuYANG/Self-supervised-CVP-MVSNet)
- ![SelfSup](https://img.shields.io/badge/Self--Surpervised-ffe169.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA2NDAgNTEyIj48cGF0aCBkPSJNNDk0LjkgOTYuMDFjLTM4Ljc4IDAtNzUuMjIgMTUuMDktMTAyLjYgNDIuNUwzMjAgMjEwLjhMMjQ3LjggMTM4LjVjLTI3LjQxLTI3LjQxLTYzLjg0LTQyLjUtMTAyLjYtNDIuNUM2NS4xMSA5Ni4wMSAwIDE2MS4xIDAgMjQxLjF2MjkuNzVjMCA4MC4wMyA2NS4xMSAxNDUuMSAxNDUuMSAxNDUuMWMzOC43OCAwIDc1LjIyLTE1LjA5IDEwMi42LTQyLjVMMzIwIDMwMS4zbDcyLjIzIDcyLjI1YzI3LjQxIDI3LjQxIDYzLjg0IDQyLjUgMTAyLjYgNDIuNUM1NzQuOSA0MTYgNjQwIDM1MC45IDY0MCAyNzAuOXYtMjkuNzVDNjQwIDE2MS4xIDU3NC45IDk2LjAxIDQ5NC45IDk2LjAxek0yMDIuNSAzMjguM2MtMTUuMzEgMTUuMzEtMzUuNjkgMjMuNzUtNTcuMzggMjMuNzVDMTAwLjQgMzUyIDY0IDMxNS42IDY0IDI3MC45di0yOS43NWMwLTQ0LjcyIDM2LjQxLTgxLjEzIDgxLjE0LTgxLjEzYzIxLjY5IDAgNDIuMDYgOC40MzggNTcuMzggMjMuNzVsNzIuMjMgNzIuMjVMMjAyLjUgMzI4LjN6TTU3NiAyNzAuOWMwIDQ0LjcyLTM2LjQxIDgxLjEzLTgxLjE0IDgxLjEzYy0yMS42OSAwLTQyLjA2LTguNDM4LTU3LjM4LTIzLjc1bC03Mi4yMy03Mi4yNWw3Mi4yMy03Mi4yNWMxNS4zMS0xNS4zMSAzNS42OS0yMy43NSA1Ny4zOC0yMy43NUM1MzkuNiAxNjAgNTc2IDE5Ni40IDU3NiAyNDEuMVYyNzAuOXoiLz48L3N2Zz4=)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314203201.png)

#### Mˆ3VSNet: Unsupervised multi-metric multi-view stereo network

- ![Publication](https://img.shields.io/badge/2021-ICIP-3a506b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.2005.00363-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2005.00363)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/whubaichuan/M3VSNet?logo=github&label=Stars)](https://github.com/whubaichuan/M3VSNet)
- ![SelfSup](https://img.shields.io/badge/Self--Surpervised-ffe169.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA2NDAgNTEyIj48cGF0aCBkPSJNNDk0LjkgOTYuMDFjLTM4Ljc4IDAtNzUuMjIgMTUuMDktMTAyLjYgNDIuNUwzMjAgMjEwLjhMMjQ3LjggMTM4LjVjLTI3LjQxLTI3LjQxLTYzLjg0LTQyLjUtMTAyLjYtNDIuNUM2NS4xMSA5Ni4wMSAwIDE2MS4xIDAgMjQxLjF2MjkuNzVjMCA4MC4wMyA2NS4xMSAxNDUuMSAxNDUuMSAxNDUuMWMzOC43OCAwIDc1LjIyLTE1LjA5IDEwMi42LTQyLjVMMzIwIDMwMS4zbDcyLjIzIDcyLjI1YzI3LjQxIDI3LjQxIDYzLjg0IDQyLjUgMTAyLjYgNDIuNUM1NzQuOSA0MTYgNjQwIDM1MC45IDY0MCAyNzAuOXYtMjkuNzVDNjQwIDE2MS4xIDU3NC45IDk2LjAxIDQ5NC45IDk2LjAxek0yMDIuNSAzMjguM2MtMTUuMzEgMTUuMzEtMzUuNjkgMjMuNzUtNTcuMzggMjMuNzVDMTAwLjQgMzUyIDY0IDMxNS42IDY0IDI3MC45di0yOS43NWMwLTQ0LjcyIDM2LjQxLTgxLjEzIDgxLjE0LTgxLjEzYzIxLjY5IDAgNDIuMDYgOC40MzggNTcuMzggMjMuNzVsNzIuMjMgNzIuMjVMMjAyLjUgMzI4LjN6TTU3NiAyNzAuOWMwIDQ0LjcyLTM2LjQxIDgxLjEzLTgxLjE0IDgxLjEzYy0yMS42OSAwLTQyLjA2LTguNDM4LTU3LjM4LTIzLjc1bC03Mi4yMy03Mi4yNWw3Mi4yMy03Mi4yNWMxNS4zMS0xNS4zMSAzNS42OS0yMy43NSA1Ny4zOC0yMy43NUM1MzkuNiAxNjAgNTc2IDE5Ni40IDU3NiAyNDEuMVYyNzAuOXoiLz48L3N2Zz4=)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314235727.png)

#### AA-RMVSNet: Adaptive Aggregation Recurrent Multi-View Stereo Network

- ![Publication](https://img.shields.io/badge/2021-ICCV-f9c74f) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/ICCV2021/papers/Wei_AA-RMVSNet_Adaptive_Aggregation_Recurrent_Multi-View_Stereo_Network_ICCV_2021_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Wei_AA-RMVSNet_Adaptive_Aggregation_ICCV_2021_supplemental.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2108.03824-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2108.03824)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/QT-Zhu/AA-RMVSNet?logo=github&label=Stars)](https://github.com/QT-Zhu/AA-RMVSNet)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314203957.png)

#### Digging into Uncertainty in Self-supervised Multi-view Stereo

- ![Publication](https://img.shields.io/badge/2021-ICCV-f9c74f) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/ICCV2021/papers/Xu_Digging_Into_Uncertainty_in_Self-Supervised_Multi-View_Stereo_ICCV_2021_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Xu_Digging_Into_Uncertainty_ICCV_2021_supplemental.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2108.12966-B31B1B?logo=arXiv&logoColor=green)](http://arxiv.org/abs/2108.12966)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/ToughStoneX/U-MVS?logo=github&label=Stars)](https://github.com/ToughStoneX/U-MVS)
- ![SelfSup](https://img.shields.io/badge/Self--Surpervised-ffe169.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA2NDAgNTEyIj48cGF0aCBkPSJNNDk0LjkgOTYuMDFjLTM4Ljc4IDAtNzUuMjIgMTUuMDktMTAyLjYgNDIuNUwzMjAgMjEwLjhMMjQ3LjggMTM4LjVjLTI3LjQxLTI3LjQxLTYzLjg0LTQyLjUtMTAyLjYtNDIuNUM2NS4xMSA5Ni4wMSAwIDE2MS4xIDAgMjQxLjF2MjkuNzVjMCA4MC4wMyA2NS4xMSAxNDUuMSAxNDUuMSAxNDUuMWMzOC43OCAwIDc1LjIyLTE1LjA5IDEwMi42LTQyLjVMMzIwIDMwMS4zbDcyLjIzIDcyLjI1YzI3LjQxIDI3LjQxIDYzLjg0IDQyLjUgMTAyLjYgNDIuNUM1NzQuOSA0MTYgNjQwIDM1MC45IDY0MCAyNzAuOXYtMjkuNzVDNjQwIDE2MS4xIDU3NC45IDk2LjAxIDQ5NC45IDk2LjAxek0yMDIuNSAzMjguM2MtMTUuMzEgMTUuMzEtMzUuNjkgMjMuNzUtNTcuMzggMjMuNzVDMTAwLjQgMzUyIDY0IDMxNS42IDY0IDI3MC45di0yOS43NWMwLTQ0LjcyIDM2LjQxLTgxLjEzIDgxLjE0LTgxLjEzYzIxLjY5IDAgNDIuMDYgOC40MzggNTcuMzggMjMuNzVsNzIuMjMgNzIuMjVMMjAyLjUgMzI4LjN6TTU3NiAyNzAuOWMwIDQ0LjcyLTM2LjQxIDgxLjEzLTgxLjE0IDgxLjEzYy0yMS42OSAwLTQyLjA2LTguNDM4LTU3LjM4LTIzLjc1bC03Mi4yMy03Mi4yNWw3Mi4yMy03Mi4yNWMxNS4zMS0xNS4zMSAzNS42OS0yMy43NSA1Ny4zOC0yMy43NUM1MzkuNiAxNjAgNTc2IDE5Ni40IDU3NiAyNDEuMVYyNzAuOXoiLz48L3N2Zz4=)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314210011.png)

#### Self-supervised multi-view stereo via effective co-segmentation and data-augmentation

- ![Publication](https://img.shields.io/badge/2021-AAAI-ffafcc) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://www.aaai.org/AAAI21Papers/AAAI-2549.XuH.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2104.05374-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2104.05374)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/ToughStoneX/Self-Supervised-MVS?logo=github&label=Stars)](https://github.com/ToughStoneX/Self-Supervised-MVS)
- ![SelfSup](https://img.shields.io/badge/Self--Surpervised-ffe169.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA2NDAgNTEyIj48cGF0aCBkPSJNNDk0LjkgOTYuMDFjLTM4Ljc4IDAtNzUuMjIgMTUuMDktMTAyLjYgNDIuNUwzMjAgMjEwLjhMMjQ3LjggMTM4LjVjLTI3LjQxLTI3LjQxLTYzLjg0LTQyLjUtMTAyLjYtNDIuNUM2NS4xMSA5Ni4wMSAwIDE2MS4xIDAgMjQxLjF2MjkuNzVjMCA4MC4wMyA2NS4xMSAxNDUuMSAxNDUuMSAxNDUuMWMzOC43OCAwIDc1LjIyLTE1LjA5IDEwMi42LTQyLjVMMzIwIDMwMS4zbDcyLjIzIDcyLjI1YzI3LjQxIDI3LjQxIDYzLjg0IDQyLjUgMTAyLjYgNDIuNUM1NzQuOSA0MTYgNjQwIDM1MC45IDY0MCAyNzAuOXYtMjkuNzVDNjQwIDE2MS4xIDU3NC45IDk2LjAxIDQ5NC45IDk2LjAxek0yMDIuNSAzMjguM2MtMTUuMzEgMTUuMzEtMzUuNjkgMjMuNzUtNTcuMzggMjMuNzVDMTAwLjQgMzUyIDY0IDMxNS42IDY0IDI3MC45di0yOS43NWMwLTQ0LjcyIDM2LjQxLTgxLjEzIDgxLjE0LTgxLjEzYzIxLjY5IDAgNDIuMDYgOC40MzggNTcuMzggMjMuNzVsNzIuMjMgNzIuMjVMMjAyLjUgMzI4LjN6TTU3NiAyNzAuOWMwIDQ0LjcyLTM2LjQxIDgxLjEzLTgxLjE0IDgxLjEzYy0yMS42OSAwLTQyLjA2LTguNDM4LTU3LjM4LTIzLjc1bC03Mi4yMy03Mi4yNWw3Mi4yMy03Mi4yNWMxNS4zMS0xNS4zMSAzNS42OS0yMy43NSA1Ny4zOC0yMy43NUM1MzkuNiAxNjAgNTc2IDE5Ni40IDU3NiAyNDEuMVYyNzAuOXoiLz48L3N2Zz4=)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314235205.png)

#### MVS2D: Efficient Multi-view Stereo via Attention-Driven 2D Convolutions

- ![Publication](https://img.shields.io/badge/2021-CoRR-b31b1b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.2104.13325-B31B1B?logo=arXiv&logoColor=green)](http://arxiv.org/abs/2104.13325)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/zhenpeiyang/MVS2D?logo=github&label=Stars)](https://github.com/zhenpeiyang/MVS2D)
- [![Webpage](https://img.shields.io/badge/Project-Page-3cba54?style=flat&logo=Google%20chrome&logoColor=white)](https://zhenpeiyang.github.io/MVS2D/)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220318010952.png)

#### IB-MVS: An Iterative Algorithm for Deep Multi-View Stereo based on Binary Decisions

- ![Publication](https://img.shields.io/badge/2021-BMVC-b98b73) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://www.bmvc2021-virtualconference.com/assets/papers/0902.pdf) [![Supp](https://img.shields.io/badge/Supplementary-ZIP-b5e48c)](https://www.bmvc2021-virtualconference.com/assets/supp/0902_supp.zip) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2111.14420-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2111.14420)
- [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/ib-mvs-an-iterative-algorithm-for-deep-multi/3d-reconstruction-on-dtu)](https://paperswithcode.com/sota/3d-reconstruction-on-dtu?p=ib-mvs-an-iterative-algorithm-for-deep-multi) [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/ib-mvs-an-iterative-algorithm-for-deep-multi/point-clouds-on-tanks-and-temples)](https://paperswithcode.com/sota/point-clouds-on-tanks-and-temples?p=ib-mvs-an-iterative-algorithm-for-deep-multi)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220318011453.png)

#### EPP-MVSNet: Epipolar-Assembling Based Depth Prediction for Multi-View Stereo

- ![Publication](https://img.shields.io/badge/2021-ICCV-f9c74f) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/ICCV2021/papers/Ma_EPP-MVSNet_Epipolar-Assembling_Based_Depth_Prediction_for_Multi-View_Stereo_ICCV_2021_paper.pdf)
- ![Huawei](https://img.shields.io/badge/MindSpore-d3d3d3?logo=huawei&logoColor=red) [![GitHub stars](https://img.shields.io/github/stars/mindspore-ai/models?logo=github&label=Stars)](https://github.com/mindspore-ai/models)
- [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/epp-mvsnet-epipolar-assembling-based-depth/3d-reconstruction-on-dtu)](https://paperswithcode.com/sota/3d-reconstruction-on-dtu?p=epp-mvsnet-epipolar-assembling-based-depth) [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/epp-mvsnet-epipolar-assembling-based-depth/point-clouds-on-tanks-and-temples)](https://paperswithcode.com/sota/point-clouds-on-tanks-and-temples?p=epp-mvsnet-epipolar-assembling-based-depth)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314210559.png)

#### NerfingMVS: Guided Optimization of Neural Radiance Fields for Indoor Multi-View Stereo

- ![Publication](https://img.shields.io/badge/2021-ICCV-f9c74f) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/ICCV2021/papers/Wei_NerfingMVS_Guided_Optimization_of_Neural_Radiance_Fields_for_Indoor_Multi-View_ICCV_2021_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-ZIP-b5e48c)](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Wei_NerfingMVS_Guided_Optimization_ICCV_2021_supplemental.zip) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2109.01129-B31B1B?logo=arXiv&logoColor=green)](http://arxiv.org/abs/2109.01129)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/weiyithu/NerfingMVS?logo=github&label=Stars)](https://github.com/weiyithu/NerfingMVS)
- [![Video](https://img.shields.io/badge/Youtube-Video-cc0000?style=flat&logo=youtube&logoColor=cc0000)](https://youtu.be/i-b5lPnYipA) [![Webpage](https://img.shields.io/badge/Project-Page-3cba54?style=flat&logo=Google%20chrome&logoColor=white)](https://weiyithu.github.io/NerfingMVS)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220318180230.png)

#### Just a Few Points Are All You Need for Multi-View Stereo: A Novel Semi-Supervised Learning Method for Multi-View Stereo

- ![Publication](https://img.shields.io/badge/2021-ICCV-f9c74f) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/ICCV2021/papers/Kim_Just_a_Few_Points_Are_All_You_Need_for_Multi-View_ICCV_2021_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Kim_Just_a_Few_ICCV_2021_supplemental.pdf)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314215026.png)

#### Learning Signed Distance Field for Multi-view Surface Reconstruction - [MVSDF]

- ![Publication](https://img.shields.io/badge/2021-ICCV-f9c74f) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Learning_Signed_Distance_Field_for_Multi-View_Surface_Reconstruction_ICCV_2021_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-ZIP-b5e48c)](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Zhang_Learning_Signed_Distance_ICCV_2021_supplemental.zip) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2108.09964-B31B1B?logo=arXiv&logoColor=green)](http://arxiv.org/abs/2108.09964)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/jzhangbs/MVSDF?logo=github&label=Stars)](https://github.com/jzhangbs/MVSDF)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314215324.png)

#### PatchMatch-RL: Deep MVS With Pixelwise Depth, Normal, and Visibility

- ![Publication](https://img.shields.io/badge/2021-ICCV-f9c74f) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/ICCV2021/papers/Lee_PatchMatch-RL_Deep_MVS_With_Pixelwise_Depth_Normal_and_Visibility_ICCV_2021_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Lee_PatchMatch-RL_Deep_MVS_ICCV_2021_supplemental.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2108.08943-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2108.08943)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/leejaeyong7/patchmatch-rl?logo=github&label=Stars)](https://github.com/leejaeyong7/patchmatch-rl)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314221024.png)

#### Deep Multi-View Stereo Gone Wild

- ![Publication](https://img.shields.io/badge/2021-3DV-277da1) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://conferences.computer.org/3dvpub/pdfs/3DV2021-5lXBZyiG3QAsRBKXHIjqU8/268800a484/268800a484.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2104.15119-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2104.15119)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/fdarmon/wild_deep_mvs?logo=github&label=Stars)](https://github.com/fdarmon/wild_deep_mvs)
- [![Webpage](https://img.shields.io/badge/Project-Page-3cba54?style=flat&logo=Google%20chrome&logoColor=white)](https://imagine.enpc.fr/~darmonf/wild_deep_mvs/)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/3%E6%88%AA%E5%B1%8F2022-03-14%2016.51.16.png)

#### HighRes-MVSNet: A Fast Multi-View Stereo Network for Dense 3D Reconstruction From High-Resolution Images

- ![Publication](https://img.shields.io/badge/2021-IEEE--Access-3a506b) [![Paper](https://img.shields.io/badge/Journal-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://ieeexplore.ieee.org/document/9319163)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314222634.png)

#### AACVP-MVSNet: Attention-aware cost volume pyramid based multi-view stereo network for 3D reconstruction. ISPRS Journal of Photogrammetry and Remote Sensing

- ![Publication](https://img.shields.io/badge/2021-ISPRS-3a506b) [![Paper](https://img.shields.io/badge/Journal-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://www.sciencedirect.com/science/article/pii/S0924271621000794) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2011.12722-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2011.12722)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/ArthasMil/AACVP-MVSNet?logo=github&label=Stars)](https://github.com/ArthasMil/AACVP-MVSNet)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314223313.png)

#### Non-local Recurrent Regularization Networks for Multi-view Stereo

- ![Publication](https://img.shields.io/badge/2021-CoRR-b31b1b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.2110.06436-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2110.06436)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314225050.png)

#### DDR-Net: Learning Multi-Stage Multi-View Stereo With Dynamic Depth Range

- ![Publication](https://img.shields.io/badge/2021-CoRR-b31b1b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.2103.14275-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2103.14275)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/Tangshengku/DDR-Net?logo=github&label=Stars)](https://github.com/Tangshengku/DDR-Net)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314225751.png)

#### IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo

- ![Publication](https://img.shields.io/badge/2021-CoRR-b31b1b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.2112.05126-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2112.05126)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/FangjinhuaWang/IterMVS?logo=github&label=Stars)](https://github.com/FangjinhuaWang/IterMVS)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220315181849.png)

#### TANDEM: Tracking and Dense Mapping in Real-time using Deep Multi-view Stereo

- ![Publication](https://img.shields.io/badge/2021-CoRL-717D40) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openreview.net/pdf?id=FzMHiDesj0I) [![Supp](https://img.shields.io/badge/Supplementary-OTHER-blue)](https://openreview.net/attachment?id=FzMHiDesj0I&name=supplementary_material) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2111.07418-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2111.07418)
- ![CPP](https://img.shields.io/badge/C%2B%2B-00599C?&logo=c%2B%2B&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/tum-vision/tandem?logo=github&label=Stars)](https://github.com/tum-vision/tandem)
- [![Video](https://img.shields.io/badge/Youtube-Video-cc0000?style=flat&logo=youtube&logoColor=cc0000)](https://youtu.be/L4C8Q6Gvl1w) [![Webpage](https://img.shields.io/badge/Project-Page-3cba54?style=flat&logo=Google%20chrome&logoColor=white)](https://vision.in.tum.de/research/vslam/tandem)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220318175420.png)

### 2022

#### Curvature-guided dynamic scale networks for Multi-view Stereo - [CDS-MVSNet]

- ![Publication](https://img.shields.io/badge/2022-ICLR-a8dadc) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openreview.net/pdf?id=_Wzj0J2xs2D) [![Supp](https://img.shields.io/badge/Supplementary-OTHER-blue)](https://openreview.net/attachment?id=_Wzj0J2xs2D&name=supplementary_material) [![Paper](http://img.shields.io/badge/arxiv-arxiv.2112.05999-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2112.05999)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/TruongKhang/cds-mvsnet?logo=github&label=Stars)](https://github.com/TruongKhang/cds-mvsnet)
- [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/curvature-guided-dynamic-scale-networks-for-1/3d-reconstruction-on-dtu)](https://paperswithcode.com/sota/3d-reconstruction-on-dtu?p=curvature-guided-dynamic-scale-networks-for-1) [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/curvature-guided-dynamic-scale-networks-for-1/point-clouds-on-tanks-and-temples)](https://paperswithcode.com/sota/point-clouds-on-tanks-and-temples?p=curvature-guided-dynamic-scale-networks-for-1)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220319005124.png)

#### TransMVSNet: Global Context-aware Multi-view Stereo Network with Transformers

- ![Publication](https://img.shields.io/badge/2022-CVPR-43aa8b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.2111.14600-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2111.14600)
- ![Other](https://img.shields.io/badge/Other-white.svg?logoColor=white&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA1MTIgNTEyIiB3aWR0aD0iMjQiIGhlaWdodD0iMjQiPjxwYXRoIGQ9Ik0yNTYgMEMxMTQuNiAwIDAgMTE0LjYgMCAyNTZzMTE0LjYgMjU2IDI1NiAyNTZzMjU2LTExNC42IDI1Ni0yNTZTMzk3LjQgMCAyNTYgMHpNMjU2IDQwMGMtMTggMC0zMi0xNC0zMi0zMnMxMy4xLTMyIDMyLTMyYzE3LjEgMCAzMiAxNCAzMiAzMlMyNzMuMSA0MDAgMjU2IDQwMHpNMzI1LjEgMjU4TDI4MCAyODZWMjg4YzAgMTMtMTEgMjQtMjQgMjRTMjMyIDMwMSAyMzIgMjg4VjI3MmMwLTggNC0xNiAxMi0yMWw1Ny0zNEMzMDggMjEzIDMxMiAyMDYgMzEyIDE5OEMzMTIgMTg2IDMwMS4xIDE3NiAyODkuMSAxNzZoLTUxLjFDMjI1LjEgMTc2IDIxNiAxODYgMjE2IDE5OGMwIDEzLTExIDI0LTI0IDI0cy0yNC0xMS0yNC0yNEMxNjggMTU5IDE5OSAxMjggMjM3LjEgMTI4aDUxLjFDMzI5IDEyOCAzNjAgMTU5IDM2MCAxOThDMzYwIDIyMiAzNDcgMjQ1IDMyNS4xIDI1OHoiLz48L3N2Zz4=) [![GitHub stars](https://img.shields.io/github/stars/MegviiRobot/TransMVSNet?logo=github&label=Stars)](https://github.com/MegviiRobot/TransMVSNet)
- [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/transmvsnet-global-context-aware-multi-view/3d-reconstruction-on-dtu)](https://paperswithcode.com/sota/3d-reconstruction-on-dtu?p=transmvsnet-global-context-aware-multi-view)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314224420.png)

#### Rethinking Depth Estimation for Multi-View Stereo: A Unified Representation and Focal Loss - [UniMVSNet]

- ![Publication](https://img.shields.io/badge/2022-CVPR-43aa8b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.2201.01501-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2201.01501)
- ![Pytorch](https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/prstrive/UniMVSNet?logo=github&label=Stars)](https://github.com/prstrive/UniMVSNet)
- [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/rethinking-depth-estimation-for-multi-view/3d-reconstruction-on-dtu)](https://paperswithcode.com/sota/3d-reconstruction-on-dtu?p=rethinking-depth-estimation-for-multi-view)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220314224703.png)

#### Generalized Binary Search Network for Highly-Efficient Multi-View Stereo - [GBi-Net]

- ![Publication](https://img.shields.io/badge/2022-CVPR-43aa8b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.2112.02338-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2112.02338)
- ![Other](https://img.shields.io/badge/Other-white.svg?logoColor=white&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA1MTIgNTEyIiB3aWR0aD0iMjQiIGhlaWdodD0iMjQiPjxwYXRoIGQ9Ik0yNTYgMEMxMTQuNiAwIDAgMTE0LjYgMCAyNTZzMTE0LjYgMjU2IDI1NiAyNTZzMjU2LTExNC42IDI1Ni0yNTZTMzk3LjQgMCAyNTYgMHpNMjU2IDQwMGMtMTggMC0zMi0xNC0zMi0zMnMxMy4xLTMyIDMyLTMyYzE3LjEgMCAzMiAxNCAzMiAzMlMyNzMuMSA0MDAgMjU2IDQwMHpNMzI1LjEgMjU4TDI4MCAyODZWMjg4YzAgMTMtMTEgMjQtMjQgMjRTMjMyIDMwMSAyMzIgMjg4VjI3MmMwLTggNC0xNiAxMi0yMWw1Ny0zNEMzMDggMjEzIDMxMiAyMDYgMzEyIDE5OEMzMTIgMTg2IDMwMS4xIDE3NiAyODkuMSAxNzZoLTUxLjFDMjI1LjEgMTc2IDIxNiAxODYgMjE2IDE5OGMwIDEzLTExIDI0LTI0IDI0cy0yNC0xMS0yNC0yNEMxNjggMTU5IDE5OSAxMjggMjM3LjEgMTI4aDUxLjFDMzI5IDEyOCAzNjAgMTU5IDM2MCAxOThDMzYwIDIyMiAzNDcgMjQ1IDMyNS4xIDI1OHoiLz48L3N2Zz4=) [![GitHub stars](https://img.shields.io/github/stars/MiZhenxing/GBi-Net?logo=github&label=Stars)](https://github.com/MiZhenxing/GBi-Net)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220315004143.png)

#### iMVS: Improving MVS Networks by Learning Depth Discontinuities

- ![Publication](https://img.shields.io/badge/2022-CoRR-b31b1b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.2203.01391-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2203.01391)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/imvs.png)

#### PatchMVSNet: Patch-wise Unsupervised Multi-View Stereo for Weakly-Textured Surface Reconstruction

- ![Publication](https://img.shields.io/badge/2022-CoRR-b31b1b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.2203.02156-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2203.02156)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220318170940.png)

#### RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering

- ![Publication](https://img.shields.io/badge/2022-CoRR-b31b1b)  [![Paper](http://img.shields.io/badge/arxiv-arxiv.2203.03949-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/2203.03949)
- ![Other](https://img.shields.io/badge/Other-white.svg?logoColor=white&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA1MTIgNTEyIiB3aWR0aD0iMjQiIGhlaWdodD0iMjQiPjxwYXRoIGQ9Ik0yNTYgMEMxMTQuNiAwIDAgMTE0LjYgMCAyNTZzMTE0LjYgMjU2IDI1NiAyNTZzMjU2LTExNC42IDI1Ni0yNTZTMzk3LjQgMCAyNTYgMHpNMjU2IDQwMGMtMTggMC0zMi0xNC0zMi0zMnMxMy4xLTMyIDMyLTMyYzE3LjEgMCAzMiAxNCAzMiAzMlMyNzMuMSA0MDAgMjU2IDQwMHpNMzI1LjEgMjU4TDI4MCAyODZWMjg4YzAgMTMtMTEgMjQtMjQgMjRTMjMyIDMwMSAyMzIgMjg4VjI3MmMwLTggNC0xNiAxMi0yMWw1Ny0zNEMzMDggMjEzIDMxMiAyMDYgMzEyIDE5OEMzMTIgMTg2IDMwMS4xIDE3NiAyODkuMSAxNzZoLTUxLjFDMjI1LjEgMTc2IDIxNiAxODYgMjE2IDE5OGMwIDEzLTExIDI0LTI0IDI0cy0yNC0xMS0yNC0yNEMxNjggMTU5IDE5OSAxMjggMjM3LjEgMTI4aDUxLjFDMzI5IDEyOCAzNjAgMTU5IDM2MCAxOThDMzYwIDIyMiAzNDcgMjQ1IDMyNS4xIDI1OHoiLz48L3N2Zz4=) [![GitHub stars](https://img.shields.io/github/stars/Boese0601/RC-MVSNet?logo=github&label=Stars)](https://github.com/Boese0601/RC-MVSNet)
- ![SelfSup](https://img.shields.io/badge/Self--Surpervised-ffe169.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA2NDAgNTEyIj48cGF0aCBkPSJNNDk0LjkgOTYuMDFjLTM4Ljc4IDAtNzUuMjIgMTUuMDktMTAyLjYgNDIuNUwzMjAgMjEwLjhMMjQ3LjggMTM4LjVjLTI3LjQxLTI3LjQxLTYzLjg0LTQyLjUtMTAyLjYtNDIuNUM2NS4xMSA5Ni4wMSAwIDE2MS4xIDAgMjQxLjF2MjkuNzVjMCA4MC4wMyA2NS4xMSAxNDUuMSAxNDUuMSAxNDUuMWMzOC43OCAwIDc1LjIyLTE1LjA5IDEwMi42LTQyLjVMMzIwIDMwMS4zbDcyLjIzIDcyLjI1YzI3LjQxIDI3LjQxIDYzLjg0IDQyLjUgMTAyLjYgNDIuNUM1NzQuOSA0MTYgNjQwIDM1MC45IDY0MCAyNzAuOXYtMjkuNzVDNjQwIDE2MS4xIDU3NC45IDk2LjAxIDQ5NC45IDk2LjAxek0yMDIuNSAzMjguM2MtMTUuMzEgMTUuMzEtMzUuNjkgMjMuNzUtNTcuMzggMjMuNzVDMTAwLjQgMzUyIDY0IDMxNS42IDY0IDI3MC45di0yOS43NWMwLTQ0LjcyIDM2LjQxLTgxLjEzIDgxLjE0LTgxLjEzYzIxLjY5IDAgNDIuMDYgOC40MzggNTcuMzggMjMuNzVsNzIuMjMgNzIuMjVMMjAyLjUgMzI4LjN6TTU3NiAyNzAuOWMwIDQ0LjcyLTM2LjQxIDgxLjEzLTgxLjE0IDgxLjEzYy0yMS42OSAwLTQyLjA2LTguNDM4LTU3LjM4LTIzLjc1bC03Mi4yMy03Mi4yNWw3Mi4yMy03Mi4yNWMxNS4zMS0xNS4zMSAzNS42OS0yMy43NSA1Ny4zOC0yMy43NUM1MzkuNiAxNjAgNTc2IDE5Ni40IDU3NiAyNDEuMVYyNzAuOXoiLz48L3N2Zz4=)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220318172139.png)

## PatchMatch-based MVS Methods

### early

#### Patchmatch stereo-stereo matching with slanted support windows

- ![Publication](https://img.shields.io/badge/2011-BMVC-b98b73) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](http://www.bmva.org/bmvc/2011/proceedings/paper14/paper14.pdf)
- ![CPP](https://img.shields.io/badge/C%2B%2B-00599C?&logo=c%2B%2B&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/ethan-li-coding/PatchMatchStereo?logo=github&label=Stars)](https://github.com/ethan-li-coding/PatchMatchStereo)

#### Pixelwise view selection for unstructured multi-view stereo - [COLMAP]

- ![Publication](https://img.shields.io/badge/2016-ECCV-f3722c) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://link.springer.com/content/pdf/10.1007%2F978-3-319-46487-9_31.pdf) ![Publication](https://img.shields.io/badge/2016-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_cvpr_2016/papers/Schonberger_Structure-From-Motion_Revisited_CVPR_2016_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-ZIP-b5e48c)](https://openaccess.thecvf.com/content_cvpr_2016/supplemental/Schonberger_Structure-From-Motion_Revisited_2016_CVPR_supplemental.zip)
- ![CPP](https://img.shields.io/badge/C%2B%2B-00599C?&logo=c%2B%2B&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/colmap/colmap?logo=github&label=Stars)](https://github.com/colmap/colmap)

#### A TV prior for high-quality scalable multi-view stereo reconstruction

- ![Publication](https://img.shields.io/badge/2016-IJCV-3a506b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://www.cs.middlebury.edu/~schar/papers/Kuhn-3DV-2014.pdf)

### 2019

#### Multi-Scale Geometric Consistency Guided Multi-View Stereo - [ACMH, ACMM]

- ![Publication](https://img.shields.io/badge/2019-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Multi-Scale_Geometric_Consistency_Guided_Multi-View_Stereo_CVPR_2019_paper.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1904.08103-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/1904.08103)
- ![CUDA](https://img.shields.io/badge/CUDA-76B900?logo=nvidia&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/GhiXu/ACMM?logo=github&label=Stars)](https://github.com/GhiXu/ACMM) ![CUDA](https://img.shields.io/badge/CUDA-76B900?logo=nvidia&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/GhiXu/ACMH?logo=github&label=Stars)](https://github.com/GhiXu/ACMH)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/acmm.png)


#### TAPA-MVS: Textureless-Aware PAtchMatch Multi-View Stereo

- ![Publication](https://img.shields.io/badge/2019-ICCV-f9c74f) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_ICCV_2019/papers/Romanoni_TAPA-MVS_Textureless-Aware_PAtchMatch_Multi-View_Stereo_ICCV_2019_paper.pdf) [![Supp](https://img.shields.io/badge/Supplementary-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Romanoni_TAPA-MVS_Textureless-Aware_PAtchMatch_ICCV_2019_supplemental.pdf) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1903.10929-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/1903.10929)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/tapamvs.png)

#### Plane completion and ﬁltering for multi-view stereo reconstruction

- ![Publication](https://img.shields.io/badge/2019-GCPR-3a506b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://dl.acm.org/doi/abs/10.1007/978-3-030-33676-9_2)


#### Pyramid Multi-View Stereo with Local Consistency - [PLC]
- ![Publication](https://img.shields.io/badge/2019-PG-3a506b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](http://graphvision.whu.edu.cn/papers/paper1245_CRC.pdf)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220320194358.png)

### 2020

#### Mesh-Guided Multi-View Stereo with Pyramid Architecture

- ![Publication](https://img.shields.io/badge/2020-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Mesh-Guided_Multi-View_Stereo_With_Pyramid_Architecture_CVPR_2020_paper.pdf)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220315181015.png)

#### Planar Prior Assisted PatchMatch Multi-View Stereo - [ACMP, ACMMP]

- ![Publication](https://img.shields.io/badge/2020-AAAI-ffafcc) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://aaai.org/ojs/index.php/AAAI/article/view/6940/6794) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1912.11744-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/1912.11744)
- ![CUDA](https://img.shields.io/badge/CUDA-76B900?logo=nvidia&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/GhiXu/ACMP?logo=github&label=Stars)](https://github.com/GhiXu/ACMP) ![CUDA](https://img.shields.io/badge/CUDA-76B900?logo=nvidia&logoColor=white) [![GitHub stars](https://img.shields.io/github/stars/GhiXu/ACMMP?logo=github&label=Stars)](https://github.com/GhiXu/ACMMP)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/acmp.png)

#### DeepC-MVS: Deep Confidence Prediction for Multi-View Stereo Reconstruction

- ![Publication](https://img.shields.io/badge/2020-3DV-277da1) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://ieeexplore.ieee.org/document/9320407) [![Paper](http://img.shields.io/badge/arxiv-arxiv.1912.00439-B31B1B?logo=arXiv&logoColor=green)](https://arxiv.org/abs/1912.00439)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/deepcmvs.png)

#### MARMVS: Matching Ambiguity Reduced Multiple View Stereo for Efficient Large Scale Scene Reconstruction

- ![Publication](https://img.shields.io/badge/2020-CVPR-43aa8b) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_MARMVS_Matching_Ambiguity_Reduced_Multiple_View_Stereo_for_Efficient_Large_CVPR_2020_paper.pdf)
- [![Video](https://img.shields.io/badge/Youtube-Video-cc0000?style=flat&logo=youtube&logoColor=cc0000)](https://www.youtube.com/watch?v=r_QZwNbi4m8)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/marmvs.png)

#### Confidence-based Large-scale Dense Multi-view Stereo - [CLD-MVS]

- ![Publication](https://img.shields.io/badge/2020-TIP-9a8c98) [![Paper](https://img.shields.io/badge/Camera--Ready-PDF-f5cac3?logo=adobeacrobatreader&logoColor=red)](https://ieeexplore.ieee.org/abstract/document/9112642/)
- ![Image](https://raw.githubusercontent.com/asvaling/image-hosting/main/img/20220320193450.png)

